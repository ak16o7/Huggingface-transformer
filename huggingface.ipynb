{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading pytorch_model.bin: 100%|██████████| 268M/268M [00:37<00:00, 7.07MB/s] \n",
      "c:\\Users\\kaana\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kaana\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 0.1556, -0.0519,  0.2708,  ...,  0.3753,  0.6188,  0.0562],\n",
       "         [ 0.5481,  0.1741,  0.2525,  ...,  0.0332,  0.5630,  0.3739],\n",
       "         [ 1.0683,  0.2151,  0.5160,  ...,  0.5362,  0.1131, -0.4140]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Summarization \n",
    "from transformers import pipeline\n",
    "#Load pre-trained summarization model from Huggingface model hub\n",
    "summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
    "\n",
    "#Define the conversation to be summarized\n",
    "conversation = '''Bob: Hi Tim, I was hoping we could talk about my salary.\n",
    "Tim: Of course, what's on your mind?\n",
    "Bob: Well, I've been with the company for a few years now and I feel like I've taken on a lot of new responsibilities since I started. I was wondering if we could discuss a raise to reflect that.\n",
    "Tim: I understand where you're coming from, Bob, but unfortunately, we're not in a position to give out raises at the moment.\n",
    "Bob: Can you explain why?\n",
    "Tim: The company has been facing some financial difficulties lately, and we need to tighten our belts a bit. Giving out raises just isn't in the budget right now.\n",
    "Bob: I see. Is there anything I can do to help the company through this difficult time?\n",
    "Tim: Actually, yes. We've been looking for ways to cut costs, and I think you could play a big role in that. If you can come up with some innovative ideas for reducing expenses, that would be a big help.\n",
    "Bob: I'm happy to do what I can to help, but I still feel like I'm not being compensated fairly for the work I'm doing.\n",
    "Tim: I understand, Bob. And I want you to know that your hard work and dedication to the company are valued. But right now, we just can't afford to give out raises.                                    \n",
    "'''\n",
    "#Use the summarization pipeline to generate a summary of the conversation\n",
    "summarizer(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Classification\n",
    "# Import necessary libraries\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Load image from URL with PIL\n",
    "url = 'https://www.akc.org/wp-content/uploads/2015/10/Basset-Hound_Puppy_Leash.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Display the image\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (3.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Load the pre-trained ViT image processor\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "#Load the pre-trained ViT model for image classification\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "#Preprocess the image using the image processor and pass the preprocessed image to the model\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "#Assign the tensor of logits\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "#Print the predicted class label\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Stable Text to Image model \n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]  \n",
    "    \n",
    "image.save(\"astronaut_rides_horse.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
